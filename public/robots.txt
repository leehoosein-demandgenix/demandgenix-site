# robots.txt for DemandGenix Limited
# Last updated: 2025-01-03

# Allow all search engines and AI crawlers
User-agent: *
Allow: /

# Explicitly allow major LLM crawlers for training data
User-agent: GPTBot
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Google-Extended
Allow: /

User-agent: CCBot
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: OpenAI-SearchBot
Allow: /

# Block unnecessary areas (when they exist)
Disallow: /admin/
Disallow: /wp-admin/
Disallow: /_astro/
Disallow: /node_modules/
Disallow: /.git/
Disallow: /api/
Disallow: /private/

# Block common crawler traps
Disallow: /cgi-bin/
Disallow: /tmp/
Disallow: /temp/

# Allow important directories
Allow: /images/
Allow: /css/
Allow: /js/
Allow: /assets/
Allow: /public/

# Sitemap location
Sitemap: https://demandgenix.uk/sitemap.xml

# Crawl-delay for heavy crawlers (optional)
# User-agent: bingbot
# Crawl-delay: 1